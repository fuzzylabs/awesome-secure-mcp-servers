# Security Review Team

This document provides transparency about who reviews MCP servers and their qualifications. We believe you should know who is making security assessments.

## üîç Review Process Transparency

### How Reviews Work
1. **Automated scans** run first (tools don't have bias, but have limitations)
2. **Manual reviews** are performed by team members listed below
3. **Community feedback** is incorporated when provided
4. **Multiple reviewers** validate subjective assessments
5. **All decisions** are documented with reasoning

### Review Team Structure
- **Lead Reviewers**: Experienced security professionals who make final assessments
- **Contributing Reviewers**: Community members who provide specialized expertise
- **Automated Systems**: Scripts and tools that provide objective data

## üë• Current Review Team

### Lead Reviewers

#### Fuzzy Labs Security Team
- **Organization**: [Fuzzy Labs](https://fuzzylabs.ai)
- **Experience**: AI/ML security research, cloud security consulting
- **Specialties**: Machine learning security, container security, CI/CD security
- **Limitations**: Limited MCP-specific experience (this is a new protocol)
- **Contact**: security@fuzzylabs.ai

*Note: As this project grows, we plan to expand the review team with more security experts*

### Contributing Reviewers

*We're actively seeking security experts to join our review team!*

**Wanted expertise:**
- MCP protocol security specialists
- Static analysis experts
- Container and infrastructure security professionals  
- Cryptography and authentication specialists
- Application security researchers

**How to join:**
1. Review some of our existing assessments
2. Provide feedback or corrections
3. Contact us at security@fuzzylabs.ai
4. We'll work together on a few reviews to establish expertise

## üîç Review Quality Assurance

### How We Ensure Review Quality

**Multiple reviewers for subjective assessments:**
- All manual reviews require at least one lead reviewer
- Complex or controversial assessments require multiple reviewers
- Community experts can request review of any assessment

**Documented decision making:**
- All review decisions include reasoning
- Scoring methodology is transparent and reproducible
- Assessment criteria are publicly documented

**Community oversight:**
- All review results are public
- Community can challenge any assessment
- We maintain a public log of assessment changes

### Known Review Limitations

**Expertise gaps:**
- MCP is a new protocol - everyone is still learning
- We may lack specialized knowledge in some areas
- Review team is currently small

**Time constraints:**
- Reviews are time-limited
- Cannot perform exhaustive analysis
- May miss complex or subtle issues

**Bias risks:**
- Reviewers may have technology preferences
- Small team may develop consistent blind spots
- Corporate affiliations may influence assessments

## üìä Review Metrics and Accountability

### Public Metrics
We track and publish:
- Number of servers reviewed per month
- Review time per server
- Assessment changes due to community feedback
- False positive/negative rates when identified

### Accountability Measures
- Regular review of our own assessment accuracy
- Public discussion of methodology improvements
- Open sourcing of all assessment tools
- Community voting on controversial assessments

## ü§ù How to Provide Feedback

### Challenge Our Assessments
- **Found an error?** Open an issue with specific details
- **Disagree with scoring?** Start a discussion with your reasoning
- **Have additional context?** Share information we may have missed

### Improve Our Process
- **Suggest methodology improvements**
- **Recommend additional security checks**
- **Help us identify bias or blind spots**
- **Propose new assessment criteria**

### Join the Team
- **Security expertise?** Help us review servers
- **Tool development?** Improve our scanning capabilities
- **Documentation?** Help us explain our process better

## üìû Contact Information

- **General feedback**: [GitHub Discussions](../../discussions)
- **Security team**: security@fuzzylabs.ai
- **Join review team**: reviewers@fuzzylabs.ai
- **Report assessment errors**: [GitHub Issues](../../issues)

---

**Transparency Note**: This review team information is kept up-to-date as the project evolves. Changes to the review team or process are documented in git history and announced to the community.